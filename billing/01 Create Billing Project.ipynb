{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"color:dodgerblue\">01 Create Billing Project</p>\n",
    "- This notebook creates the architecture required to analyse an AWS billing \"standard data export\"\n",
    "- An example \"standard data export\" csv file is provided for this lab\n",
    "- Granularity is set to \"monthly\" and resource IDs are included in the CSV file\n",
    "  \n",
    "(Jupyter Notebook developed with Kernel Python 3.11.6)\n",
    "<hr style=\"border:1px dotted; color:floralwhite\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:deeppink\">GETTING STARTED</span>\n",
    "# Client requirements for this Jupyter Notebook Lab (macOS)\n",
    "- *See <span style=\"color:gold\">Appendix - Jupyter Install Requirements (macOS)</span> at the bottom of this lab to install macOS requirements, windows requirements will be similar, apart from Homebrew.*  \n",
    "- These requirements are generic and allow you to run Python notebooks, use Boto3, etc - they are simply to get your local environment in a state that can support Jupyter Notebooks and not specific to this lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px dotted\">\n",
    "<hr style=\"border:1px dotted;color:greenyellow\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"color:DarkTurquoise\">Billing Prerequisites</p>\n",
    "### <p style=\"color:DarkTurquoise\">NOTE we are using ap-southeast-2</p>\n",
    "No other architecture prerequisites required.\n",
    "Any \"standard data export\" csv file can be used with this project, however one is provided in the resources folder as a sample.  \n",
    "To create your own, do the following:\n",
    "- In an AWS account, go to the Billing and Cost Management console\n",
    "- Go to Data Exports (option in left hand column)\n",
    "- Create an export\n",
    "- Select \"Standard data export\"\n",
    "- Select CUR 2.0\n",
    "- Check \"Include resource IDs\" only\n",
    "- Select \"Monthly\" as time granularity\n",
    "- Select \"CSV\" as the file format\n",
    "- Typically 114 columns should be included (ie all columns, if more no worries)\n",
    "- Choose an S3 bucket etc\n",
    "- Wait for it to be created\n",
    "- Use your file as follows, either:\n",
    "  - Replace the file in the resources/datasouces folder of this lab with yours, ensuring the name is the same; or\n",
    "  - When invoking the lambda, pass in the bucket location and file name of your own file (assuming its in the same account and region of the lambda)\n",
    "\n",
    "### Columns\n",
    "https://docs.aws.amazon.com/cur/latest/userguide/table-dictionary-cur2.html#cur2-column-groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style scoped>\n",
    "table {\n",
    "  font-size: 10px;\n",
    "}\n",
    "</style>\n",
    "| **Field Name** | **Data Type** | **Description** |\n",
    "|--------------|------------|--------------|\n",
    "|bill_bill_type|String|The type of bill that this report covers.|\n",
    "|bill_billing_entity|String|Helps you identify whether your invoices or transactions are for AWS Marketplace or for purchases of other AWS services.|\n",
    "|bill_billing_period_end_date|Timestamp|The end date of the billing period that is covered by this report, in UTC. The format is YYYY-MM-DDTHH:mm:ssZ.|\n",
    "|bill_billing_period_start_date|Timestamp|The start date of the billing period that is covered by this report, in UTC. The format is YYYY-MM-DDTHH:mm:ssZ.|\n",
    "|bill_invoice_id|String|The ID associated with a specific line item. Until the report is final, the InvoiceId is blank.|\n",
    "|bill_invoicing_entity|String|The AWS entity that issues the invoice.|\n",
    "|bill_payer_account_id|String|The account ID of the paying account. For an organization in AWS Organizations, this is the account ID of the management account.|\n",
    "|bill_payer_account_name|String|The account name of the paying account. For an organization in AWS Organizations, this is the name of the management account.|\n",
    "|cost_category|Map|Cost Category entries are automatically populated when you create a Cost Category and categorization rule. These entries include user-defined Cost Category names as keys, and corresponding Cost Category values|\n",
    "|discount|Map|A map column that contains key-value pairs of additional discount data for a given line item when applicable.|\n",
    "|discount_bundled_discount|Number|The bundled discount applied to the line item. A bundled discount is a usage-based discount that provides free or discounted usage of a service or feature based on the usage of another service or feature.|\n",
    "|discount_total_discount|Number|The sum of all the discount columns for the corresponding line item.|\n",
    "|identity_line_item_id|String|This field is generated for each line item and is unique in a given partition. This does not guarantee that the field will be unique across an entire delivery (that is, all partitions in an update) of the AWS CUR. The line item ID isn't consistent between different Cost and Usage Reports and can't be used to identify the same line item across different reports.|\n",
    "|identity_time_interval|String|The time interval that this line item applies to, in the following format: YYYY-MM-DDTHH:mm:ssZ/YYYY-MM-DDTHH:mm:ssZ. The time interval is in UTC and can be either daily or hourly, depending on the granularity of the report.|\n",
    "|line_item_availability_zone|String|The Availability Zone that hosts this line item.|\n",
    "|line_item_blended_cost|Number|The BlendedRate multiplied by the UsageAmount.|\n",
    "|line_item_blended_rate|String|The BlendedRate is the average cost incurred for each SKU across an organization.|\n",
    "|line_item_currency_code|String|The currency that this line item is shown in. All AWS customers are billed in US dollars by default. To change your billing currency, see Changing which currency you use to pay your bill in the AWS Billing User Guide.|\n",
    "|line_item_legal_entity|String|The Seller of Record of a specific product or service. In most cases, the invoicing entity and legal entity are the same. The values might differ for third-party AWS Marketplace transactions.|\n",
    "|line_item_line_item_description|String|The description of the line item type.|\n",
    "|line_item_line_item_type|String|The type of charge covered by this line item.|\n",
    "|line_item_net_unblended_cost|Number|The actual after-discount cost that you're paying for the line item.|\n",
    "|line_item_net_unblended_rate|String|The actual after-discount rate that you're paying for the line item.|\n",
    "|line_item_normalization_factor|Number|As long as the instance has shared tenancy, AWS can apply all Regional Linux or Unix Amazon EC2 and Amazon RDS RI discounts to all instance sizes in an instance family and AWS Region. This also applies to RI discounts for member accounts in an organization. All new and existing Amazon EC2 and Amazon RDS size-flexible RIs are sized according to a normalization factor, based on the instance size.|\n",
    "|line_item_normalized_usage_amount|Number|The amount of usage that you incurred, in normalized units, for size-flexible RIs. The NormalizedUsageAmount is equal to UsageAmount multiplied by NormalizationFactor.|\n",
    "|line_item_operation|String|The specific AWS operation covered by this line item. This describes the specific usage of the line item.|\n",
    "|line_item_product_code|String|The code of the product measured.|\n",
    "|line_item_resource_id|String|If you chose to include individual resource IDs in your report, this column contains the ID of the resource that you provisioned.|\n",
    "|line_item_tax_type|String|The type of tax that AWS applied to this line item.|\n",
    "|line_item_unblended_cost|Number|The UnblendedCost is the UnblendedRate multiplied by the UsageAmount.|\n",
    "|line_item_unblended_rate|String|In consolidated billing for accounts using AWS Organizations, the unblended rate is the rate associated with an individual account's service usage. For Amazon EC2 and Amazon RDS line items that have an RI discount applied to them, the UnblendedRate is zero. Line items with an RI discount have a LineItemType of DiscountedUsage.|\n",
    "|line_item_usage_account_id|String|The account ID of the account that used this line item. For organizations, this can be either the management account or a member account. You can use this field to track costs or usage by account.|\n",
    "|line_item_usage_account_name|String|The name of the account that used this line item. For organizations, this can be either the management account or a member account. You can use this field to track costs or usage by account.|\n",
    "|line_item_usage_amount|Number|The amount of usage that you incurred during the specified time period. For size-flexible Reserved Instances, use the reservation_total_reserved_units column instead. Certain subscription charges will have a UsageAmount of 0.|\n",
    "|line_item_usage_end_date|Timestamp|The end date and time for the line item in UTC, exclusive. The format is YYYY-MM-DDTHH:mm:ssZ.|\n",
    "|line_item_usage_start_date|Timestamp|The start date and time for the line item in UTC, inclusive. The format is YYYY-MM-DDTHH:mm:ssZ.|\n",
    "|line_item_usage_type|String|The usage details of the line item.|\n",
    "|pricing_currency|String|The currency that the pricing data is shown in.|\n",
    "|pricing_lease_contract_length|String|The length of time that your RI is reserved for.|\n",
    "|pricing_offering_class|String|The offering class of the Reserved Instance.|\n",
    "|pricing_public_on_demand_cost|Number|The total cost for the line item based on public On-Demand Instance rates. If you have SKUs with multiple On-Demand public costs, the equivalent cost for the highest tier is displayed. For example, services offering free-tiers or tiered pricing.|\n",
    "|pricing_public_on_demand_rate|String|The public On-Demand Instance rate in this billing period for the specific line item of usage. If you have SKUs with multiple On-Demand public rates, the equivalent rate for the highest tier is displayed. For example, services offering free-tiers or tiered pricing.|\n",
    "|pricing_purchase_option|String|How you chose to pay for this line item. Valid values are All Upfront, Partial Upfront, and No Upfront.|\n",
    "|pricing_rate_code|String|A unique code for a product/ offer/ pricing-tier combination. The product and term combinations can have multiple price dimensions, such as a free tier, low-use tier, and high-use tier.|\n",
    "|pricing_rate_id|String|The ID of the rate for a line item.|\n",
    "|pricing_term|String|Whether your AWS usage is Reserved or On-Demand.|\n",
    "|pricing_unit|String|The pricing unit that AWS used for calculating your usage cost. For example, the pricing unit for Amazon EC2 instance usage is in hours.|\n",
    "|product|Map|A map column for where each key-value pair is an additional product attribute and its value.|\n",
    "|product_comment|String|A comment regarding the product.|\n",
    "|product_fee_code|String|The code that refers to the fee.|\n",
    "|product_fee_description|String|The description for the product fee.|\n",
    "|product_from_location|String|Describes the location where the usage originated from.|\n",
    "|product_from_location_type|String|Describes the location type where the usage originated from.|\n",
    "|product_from_region_code|String|Describes the source Region code for the AWS service.|\n",
    "|product_instance_family|String|Describes your Amazon EC2 instance family. Amazon EC2 provides you with a large number of options across 10 different instance types, each with one or more size options, organized into distinct instance families optimized for different types of applications.|\n",
    "|product_instance_type|String|Describes the instance type, size, and family, which define the CPU, networking, and storage capacity of your instance.|\n",
    "|product_instancesku|String|The SKU of the product instance|\n",
    "|product_location|String|Describes the location that your resource resides in.|\n",
    "|product_location_type|String|Describes the location type of your task.|\n",
    "|product_operation|String|Describes the specific AWS operation that this line item covers.|\n",
    "|product_pricing_unit|String|The smallest billing unit for an AWS service. For example, 0.01c per API call.|\n",
    "|product_product_family|String|The category for the type of product.|\n",
    "|product_region_code|String|A Region is a physical location around the world where data centers are clustered. AWS calls each group of logical data centers an Availability Zone (AZ). Each AWS Region consists of multiple, isolates, and physically separate AZs within a geographical area. The Region code attribute has the same name as an AWS Region, and specifies where the AWS service is available.|\n",
    "|product_servicecode|String|This identifies the specific AWS service to the customer as a unique short abbreviation.|\n",
    "|product_sku|String|A unique code for a product. The SKU is created by combining the ProductCode, UsageType, and Operation. For size-flexible RIs, the SKU uses the instance that was used.|\n",
    "|product_to_location|String|Describes the location usage destination.|\n",
    "|product_to_location_type|String|Describes the destination location of the service usage.|\n",
    "|product_to_region_code|String|Describes the source Region code for the AWS service.|\n",
    "|product_usagetype|String|Describes the usage details of the line item.|\n",
    "|reservation_amortized_upfront_cost_for_usage|Number|The initial upfront payment for all upfront RIs and partial upfront RIs amortized for usage time. The value is equal to: RIAmortizedUpfrontFeeForBillingPeriod * The normalized usage amount for DiscountedUsage line items / The normalized usage amount for the RIFee. Because there are no upfront payments for no upfront RIs, the value for a no upfront RI is 0. We do not provide this value for Dedicated Host reservations at this time. The change will be made in a future update.|\n",
    "|reservation_amortized_upfront_fee_for_billing_period|Number|Describes how much of the upfront fee for this reservation is costing you for the billing period. The initial upfront payment for all upfront RIs and partial upfront RIs, amortized over this month. Because there are no upfront fees for no upfront RIs, the value for no upfront RIs is 0. We do not provide this value for Dedicated Host reservations at this time. The change will be made in a future update.|\n",
    "|reservation_availability_zone|String|The Availability Zone of the resource that is associated with this line item.|\n",
    "|reservation_effective_cost|Number|The sum of both the upfront and hourly rate of your RI, averaged into an effective hourly rate. EffectiveCost is calculated by taking the amortizedUpfrontCostForUsage and adding it to the recurringFeeForUsage.|\n",
    "|reservation_end_time|String|The end date of the associated RI lease term.|\n",
    "|reservation_modification_status|String|Shows whether the RI lease was modified or if it is unaltered.|\n",
    "|reservation_net_amortized_upfront_cost_for_usage|Number|The initial upfront payment for All Upfront RIs and Partial Upfront RIs amortized for usage time, if applicable.|\n",
    "reservation_net_amortized_upfront_fee_for_billing_period|Number|The cost of the reservation's upfront fee for the billing period.|\n",
    "|reservation_net_effective_cost|Number|The sum of both the upfront fee and the hourly rate of your RI, averaged into an effective hourly rate.|\n",
    "|reservation_net_recurring_fee_for_usage|Number|The after-discount cost of the recurring usage fee.|\n",
    "|reservation_net_unused_amortized_upfront_fee_for_billing_period|Number|The net unused amortized upfront fee for the billing period.|\n",
    "|reservation_net_unused_recurring_fee|Number|The recurring fees associated with unused reservation hours for Partial Upfront and No Upfront RIs after discounts.|\n",
    "|reservation_net_upfront_value|Number|The upfront value of the RI with discounts applied.|\n",
    "|reservation_normalized_units_per_reservation|String|The number of normalized units for each instance of a reservation subscription.|\n",
    "|reservation_number_of_reservations|String|The number of reservations that are covered by this subscription. For example, one RI subscription might have four associated RI reservations.|\n",
    "|reservation_recurring_fee_for_usage|Number|The recurring fee amortized for usage time, for partial upfront RIs and no upfront RIs. The value is equal to: The unblended cost of the RIFee * The sum of the normalized usage amount of Usage line items / The normalized usage amount of the RIFee for size flexible Reserved Instances. Because all upfront RIs don't have recurring fee payments greater than 0, the value for all upfront RIs is 0.|\n",
    "|reservation_reservation_a_r_n|String|The Amazon Resource Name (ARN) of the RI that this line item benefited from. This is also called the \"RI Lease ID\". This is a unique identifier of this particular AWS Reserved Instance. The value string also contains the AWS service name and the Region where the RI was purchased.|\n",
    "|reservation_start_time|String|The start date of the term of the associated Reserved Instance.|\n",
    "|reservation_subscription_id|String|A unique identifier that maps a line item with the associated offer. We recommend you use the RI ARN as your identifier of an AWS Reserved Instance, but both can be used.|\n",
    "|reservation_total_reserved_normalized_units|String|The total number of reserved normalized units for all instances for a reservation subscription. AWS computes total normalized units by multiplying the reservation_normalized_units_per_reservation with reservation_number_of_reservations.|\n",
    "|reservation_total_reserved_units|String|TotalReservedUnits populates for both Fee and RIFee line items with distinct values. Fee line items: The total number of units reserved, for the total quantity of leases purchased in your subscription for the entire term. This is calculated by multiplying the NumberOfReservations with UnitsPerReservation. For example, 5 RIs x 744 hours per month x 12 months = 44,640. RIFee line items (monthly recurring costs): The total number of available units in your subscription, such as the total number of Amazon EC2 hours in a specific RI subscription. For example, 5 RIs x 744 hours = 3,720.|\n",
    "|reservation_units_per_reservation|String|UnitsPerReservation populates for both Fee and RIFee line items with distinct values. Fee line items: The total number of units reserved for the subscription, such as the total number of RI hours purchased for the term of the subscription. For example 744 hours per month x 12 months = 8,928 total hours/units. RIFee line items (monthly recurring costs): The total number of available units in your subscription, such as the total number of Amazon EC2 hours in a specific RI subscription. For example, 1 unit x 744 hours = 744.|\n",
    "|reservation_unused_amortized_upfront_fee_for_billing_period|Number|The amortized-upfront-fee-for-billing-period-column amortized portion of the initial upfront fee for all upfront RIs and partial upfront RIs. Because there are no upfront payments for no upfront RIs, the value for no upfront RIs is 0. We do not provide this value for Dedicated Host reservations at this time. The change will be made in a future update.|\n",
    "|reservation_unused_normalized_unit_quantity|Number|The number of unused normalized units for a size-flexible Regional RI that you didn't use during this billing period|\n",
    "|reservation_unused_quantity|Number|The number of RI hours that you didn't use during this billing period.|\n",
    "|reservation_unused_recurring_fee|Number|The recurring fees associated with your unused reservation hours for partial upfront and no upfront RIs. Because all upfront RIs don't have recurring fees greater than 0, the value for All Upfront RIs is 0.|\n",
    "|reservation_upfront_value|Number|The upfront price paid for your AWS Reserved Instance. For no upfront RIs, this value is 0.|\n",
    "|resource_tags|Map|A map where each entry is a resource tag key-value pair. This can be used to find information about the specific resources covered by a line item.|\n",
    "|savings_plan_amortized_upfront_commitment_for_billing_period|String|The amount of upfront fee a Savings Plan subscription is costing you for the billing period. The initial upfront payment for All Upfront Savings Plan and Partial Upfront Savings Plan amortized over the current month. For No Upfront Savings Plan, the value is 0.|\n",
    "|savings_plan_end_time|String|The expiration date for the Savings Plan agreement.|\n",
    "|savings_plan_instance_type_family|String|The instance family that is associated with the specified usage.|\n",
    "|savings_plan_net_amortized_upfront_commitment_for_billing_period|Number|The cost of a Savings Plan subscription upfront fee for the billing period.|\n",
    "|savings_plan_net_recurring_commitment_for_billing_period|Number|The net unblended cost of the Savings Plan fee.|\n",
    "|savings_plan_net_savings_plan_effective_cost|Number|The effective cost for Savings Plans, which is your usage divided by the fees.|\n",
    "|savings_plan_offering_type|String|Describes the type of Savings Plan purchased.|\n",
    "|savings_plan_payment_option|String|The payment options available for your Savings Plan.|\n",
    "|savings_plan_purchase_term|String|Describes the duration, or term, of the Savings Plan.|\n",
    "|savings_plan_recurring_commitment_for_billing_period|Number|The monthly recurring fee for your Savings Plan subscriptions. For example, the recurring monthly fee for a Partial Upfront Savings Plan or No Upfront Savings Plan.|\n",
    "|savings_plan_region|String|The AWS Region (geographic area) that hosts your AWS services. You can use this field to analyze spend across a particular AWS Region.|\n",
    "|savings_plan_savings_plan_a_r_n|String|The unique Savings Plan identifier.|\n",
    "|savings_plan_savings_plan_effective_cost|Number|The proportion of the Savings Plan monthly commitment amount (upfront and recurring) that is allocated to each usage line.|\n",
    "savings_plan_savings_plan_rate|String|The Savings Plan rate for the usage.|\n",
    "|savings_plan_start_time|String|The start date of the Savings Plan agreement.|\n",
    "|savings_plan_total_commitment_to_date|Number|The total amortized upfront commitment and recurring commitment to date, for that hour.|\n",
    "|savings_plan_used_commitment|Number|The total dollar amount of the Savings Plan commitment used. (SavingsPlanRate multiplied by usage)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px dotted;color:DarkTurquoise\">\n",
    "<hr style=\"border:1px dotted;color:greenyellow\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"color:greenyellow\">Create backend architecture needed to support CostOpt</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"color:greenyellow\">Lets Create Clients and Variables</p>\n",
    "- We do these setup cells here because we can then use the vars and clients to clean up resources later without having to run multiple cells if we lose the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Move to the next cell ->\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "import random\n",
    "import os\n",
    "\n",
    "# region\n",
    "myRegion='ap-southeast-2'\n",
    "myAccountNumber = boto3.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "\n",
    "# set up a boto3 session using a profile that is able to create services in the region\n",
    "# this is typically a developer profile or deployment profile\n",
    "sessionBoto3 = boto3.Session(profile_name=\"default\", region_name=myRegion)\n",
    "\n",
    "# names for services we will create below\n",
    "# s3 bucket - MUST BE A UNIQUE NAME so we randomise a couple of numbers to be sure\n",
    "myBucketCostOpt='doit-costopt-bucket-' + str(random.randint(0, 1000)) + '-' + str(random.randint(0, 1000))\n",
    "myBucketFolder='dataexport_cur2.0'\n",
    "\n",
    "# github url for markdown file content\n",
    "myGitHubURL='https://github.com/SimonDdraig/labs/blob/main/billing/resources/optimisations/dataworkloads/rds/'\n",
    "\n",
    "# iam\n",
    "myRoleLambda1=\"doit-costopt-lambda-role\"\n",
    "myPolicyLambda1=\"doit-costopt-lambda-s3-policy\"\n",
    "myRoleLambda1ARN='RETRIEVED FROM ROLE BELOW ONCE CREATED'\n",
    "myRoleDataBrew=\"doit-costopt-databrew-service-role\"\n",
    "myPolicyDataBrew=\"doit-costopt-databrew-service-policy\"\n",
    "myRoleDataBrewARN='RETRIEVED FROM ROLE BELOW ONCE CREATED'\n",
    "\n",
    "# lambda\n",
    "myLambda1='doit-costopt-process-csv-fn'\n",
    "myLambda1ARN='RETRIEVED FROM LAMBDA BELOW ONCE QUERIED'\n",
    "\n",
    "# databrew\n",
    "myDataSet=\"doit-costopt-databrew-dataset\"\n",
    "myDataSetARN=\"RETRIEVED FROM OBJECT BELOW ONCE CREATED\"\n",
    "myRecipe=\"doit-costopt-databrew-recipe\"\n",
    "myProject=\"doit-costopt-databrew-project\"\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:ForestGreen\">RECIPE</span>\n",
    "## <span style=\"color:ForestGreen\">Create a recipe</span>\n",
    "- create a recipe to perform transformations on our dataset\n",
    "- if creating a recipe via the console, it can obly be created via a project session\n",
    "- however we can create one directly in code that we can then add to a project we also create\n",
    "- this recipe can be played with in a project, reviewed, updated, and published if ready for production\n",
    "- the following steps are being applied to demonstrate just a very small handful of transformations\n",
    "  - UPPER_CASE - upper case the order status column\n",
    "  - CASE_OPERATION - NEW COLUMN - giving the order status unique values a number to represent the text\n",
    "  - UPPER_CASE - CONDITION - upper case the returned status when the feedback score is < 3\n",
    "  - REPLACE_BETWEEN_POSITIONS - obfuscation of credit card number\n",
    "  - REPLACE_PATTERN - obfuscation of email\n",
    "- https://docs.aws.amazon.com/databrew/latest/dg/recipe-actions.pii.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:ForestGreen\">RECIPE</span>\n",
    "## <span style=\"color:ForestGreen\">Create a recipe</span>\n",
    "- create a recipe to perform transformations on our dataset\n",
    "- if creating a recipe via the console, it can obly be created via a project session\n",
    "- however we can create one directly in code that we can then add to a project we also create\n",
    "- this recipe can be played with in a project, reviewed, updated, and published if ready for production\n",
    "- the following steps are being applied to demonstrate just a very small handful of transformations\n",
    "  - UPPER_CASE - upper case the order status column\n",
    "  - CASE_OPERATION - NEW COLUMN - giving the order status unique values a number to represent the text\n",
    "  - UPPER_CASE - CONDITION - upper case the returned status when the feedback score is < 3\n",
    "  - REPLACE_BETWEEN_POSITIONS - obfuscation of credit card number\n",
    "  - REPLACE_PATTERN - obfuscation of email\n",
    "- https://docs.aws.amazon.com/databrew/latest/dg/recipe-actions.pii.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Move to the next cell ->\n"
     ]
    }
   ],
   "source": [
    "# local client path for resources\n",
    "# these are resources required by this lab and will be later uploaded to the cloud\n",
    "myLocalPathForResources='/Users/simondavies/Documents/GitHub/labs/billing/resources/'\n",
    "\n",
    "# jupypter notebook path if notebook is used in AWS for example\n",
    "#myLocalPathForResources='/home/ec2-user/SageMaker/labs/billing/resources/'\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create required clients to AWS SDK for Python (Boto3) to create, configure, and manage AWS services\n",
    "- https://boto3.amazonaws.com/v1/documentation/api/latest/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Move to the next cell ->\n"
     ]
    }
   ],
   "source": [
    "# s3\n",
    "s3 = sessionBoto3.client('s3')\n",
    "\n",
    "# lambda\n",
    "lambdac = boto3.client('lambda', region_name=myRegion)\n",
    "\n",
    "# iam\n",
    "iam = sessionBoto3.client('iam')\n",
    "\n",
    "# logs (cloudwatch)\n",
    "logs = boto3.client('logs', region_name=myRegion)\n",
    "\n",
    "# databrew\n",
    "databrew = sessionBoto3.client('databrew')\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tags for all services that are created - you can never have too many tags!\n",
    "  - make sure you have a tagging policy in place\n",
    "  - https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_tag-policies.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Move to the next cell ->\n"
     ]
    }
   ],
   "source": [
    "# define tags added to all services we create\n",
    "# best practice tagging of all resources should be used at all times\n",
    "myTags = [\n",
    "    {\"Key\": \"env\", \"Value\": \"non_prod\"},\n",
    "    {\"Key\": \"owner\", \"Value\": \"doit_lab\"},\n",
    "    {\"Key\": \"project\", \"Value\": \"doit_costopt-lab\"},\n",
    "    {\"Key\": \"author\", \"Value\": \"simon\"},\n",
    "]\n",
    "myTagsDct = {\n",
    "    \"env\": \"non_prod\",\n",
    "    \"owner\": \"doit_lab\",\n",
    "    \"project\": \"doit_costopt-lab\",\n",
    "    \"author\": \"simon\",\n",
    "}\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px dotted;color:greenyellow\">\n",
    "<hr style=\"border:1px dotted;color:crimson\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"color:crimson\">Create S3 Bucket</p>\n",
    "- defaults used, will use sse-s3 encryption and block public access\n",
    "- bucket is used to upload the data file we need as a resource for the costopt dataset\n",
    "- also used to store output from costopt job runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Move to the next cell ->\n"
     ]
    }
   ],
   "source": [
    "# create bucket\n",
    "# don't change this region, the condition is just checking how to create the bucket based on the region we're working in\n",
    "if (myRegion != 'us-east-1'):\n",
    "    s3.create_bucket(\n",
    "        Bucket=myBucketCostOpt, CreateBucketConfiguration={\"LocationConstraint\": myRegion}\n",
    "    )\n",
    "else:\n",
    "    s3.create_bucket(\n",
    "        Bucket=myBucketCostOpt\n",
    "    )\n",
    "\n",
    "s3.put_bucket_tagging(Bucket=myBucketCostOpt, Tagging={\"TagSet\": myTags})\n",
    "\n",
    "# create a \"folder\" to upload the file to and where lambda gets it from - really keys as S3 is flat\n",
    "s3.put_object(Bucket=myBucketCostOpt, Key=\"{}/\".format(myBucketFolder))\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- upload resource files to s3 that will be used as a datasource for the lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploading: monthly-00001.csv\n",
      "uploaded: monthly-00001.csv to doit-costopt-bucket-396-484/dataexport_cur2.0\n",
      "Done! Move to the next cell ->\n"
     ]
    }
   ],
   "source": [
    "# Upload each file to the S3 bucket\n",
    "myDataSourceFile='{}/monthly-00001.csv'.format(myBucketFolder)\n",
    "filename = os.path.basename(myDataSourceFile)\n",
    "\n",
    "files = [\n",
    "    {\n",
    "        's3key': myDataSourceFile,\n",
    "        'localpath': '{}/datasource/{}'.format(myLocalPathForResources,filename)\n",
    "    }\n",
    "]\n",
    "\n",
    "for file in files:\n",
    "    print ('uploading: {}'.format(filename))\n",
    "    s3.upload_file(file['localpath'], myBucketCostOpt, file['s3key'], ExtraArgs={'StorageClass': 'STANDARD'})\n",
    "    print ('uploaded: {} to bucket {}/{}/{}'.format(filename,myBucketCostOpt,myBucketFolder,filename))\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px dotted;color:crimson\">\n",
    "<hr style=\"border:1px dotted;color:orchid\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"color:orchid\">Create IAM</p>\n",
    "- roles and policies that allow services to interact with other services\n",
    "- https://docs.aws.amazon.com/databrew/latest/dg/setting-up-iam-policies-for-costopt.html\n",
    "\n",
    "### <p style=\"color:orchid\">Lambda 1 IAM</p>\n",
    "- allows lambda to create log group and stream and write logs to cloudwatch\n",
    "- read from s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Move to the next cell ->\n"
     ]
    }
   ],
   "source": [
    "# myRoleLambda1\n",
    "# trust policy for the role\n",
    "roleTrust = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\"Service\": \"lambda.amazonaws.com\"},\n",
    "            \"Action\": \"sts:AssumeRole\",\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "# define inline policy\n",
    "policyJson = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"logs:CreateLogGroup\",\n",
    "                \"logs:CreateLogStream\",\n",
    "                \"logs:PutLogEvents\",\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:logs:*:*:log-group:/aws/lambda/*\",\n",
    "                \"arn:aws:logs:*:*:log-group:/aws/lambda/*:log-stream:*\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:PutObject\",\n",
    "                \"s3:ListBucket\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                f\"arn:aws:s3:::{myBucketCostOpt}\",\n",
    "                f\"arn:aws:s3:::{myBucketCostOpt}/*\"\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "# create inline policy\n",
    "policy = iam.create_policy(\n",
    "    PolicyName=myPolicyLambda1,\n",
    "    PolicyDocument=json.dumps(policyJson),\n",
    "    Description=\"Policy for costopt\",\n",
    "    Tags=[\n",
    "        *myTags,\n",
    "    ],\n",
    ")\n",
    "\n",
    "# create role\n",
    "role = iam.create_role(\n",
    "    RoleName=myRoleLambda1,\n",
    "    AssumeRolePolicyDocument=json.dumps(roleTrust),\n",
    "    Description=\"Role for costopt lambda\",\n",
    "    Tags=[\n",
    "        *myTags,\n",
    "    ],\n",
    ")\n",
    "\n",
    "# attach inline policies to role\n",
    "response = iam.attach_role_policy(\n",
    "    RoleName=role[\"Role\"][\"RoleName\"], PolicyArn=policy[\"Policy\"][\"Arn\"]\n",
    ")\n",
    "\n",
    "myRoleLambda1ARN = role['Role']['Arn']\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:LightSkyBlue\">Create Lambda</span>\n",
    "- NOTE a zip file is already provided in this lab. \n",
    "- You DO NOT NEED to create your own zip file.\n",
    "- However, if you want to edit the lambda, follow below to create an amended zip file \n",
    "  - You need to create the zip file from the lambda resource folder as create lambda function requires a zipped file\n",
    "  - You can do this from a terminal window as long as you have cd'ed to the folder that contains the function code\n",
    "    - Eg you need to be in the folder that contains the lambda function code (and all of the libraries if any are required) ...\n",
    "      - *zip -r doit-costopt-process-csv-fn.zip .*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:LightSkyBlue\">Create Lambda 1 - doit-costopt-process-csv-fn</span>\n",
    "- create a lambda to process a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Move to the next cell ->\n"
     ]
    }
   ],
   "source": [
    "# define vars\n",
    "myLambdaZip='{}lambda/{}.zip'.format(myLocalPathForResources,myLambda1)\n",
    "\n",
    "# Loads the zip file as binary code. \n",
    "with open(myLambdaZip, 'rb') as f: \n",
    "    code = f.read()\n",
    "    \n",
    "# create lambda\n",
    "myLambdaFunction = lambdac.create_function(\n",
    "    FunctionName=myLambda1,\n",
    "    Runtime='python3.12',\n",
    "    Role=myRoleLambda1ARN,\n",
    "    Handler='{}.lambda_handler'.format(myLambda1),\n",
    "    Code={'ZipFile':code},\n",
    "    Description='processes a csv file of format AWS cur 2.0 to find cost optimisation suggestions',\n",
    "    Timeout=30,\n",
    "    MemorySize=128,\n",
    "    Publish=True,\n",
    "    PackageType='Zip',\n",
    "    Environment={\n",
    "        'Variables': {\n",
    "            'BUCKET_NAME': '{}'.format(myBucketCostOpt,myBucketFolder),\n",
    "            'FILE_KEY': '{}/{}'.format(myBucketFolder, filename)\n",
    "            'GITHUB': '{}'.format(myGitHubURL)\n",
    "        }\n",
    "    },\n",
    "    Tags=myTagsDct,\n",
    "    Architectures=[\n",
    "        'x86_64',\n",
    "    ],\n",
    "    LoggingConfig={\n",
    "        'LogFormat': 'JSON',\n",
    "        'ApplicationLogLevel': 'INFO',\n",
    "        'SystemLogLevel': 'WARN'\n",
    "    }\n",
    ")\n",
    "\n",
    "myLambda1ARN=myLambdaFunction['FunctionArn']\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- log group for lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Move to the next cell ->\n"
     ]
    }
   ],
   "source": [
    "logs.create_log_group(\n",
    "    logGroupName='/aws/lambda/' + myLambda1,\n",
    "    tags=myTagsDct\n",
    ")\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px dotted;color:orchid\">\n",
    " \n",
    "# <span style=\"color:greenyellow\">The following is not required to do a cost opt, but if the cells are run, it will create a dataset in databrew and allow you to view the data in a databrew project</span>\n",
    "\n",
    "<hr style=\"border:1px dotted;color:LightSkyBlue\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:LightSkyBlue\">DATABREW</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"color:LightSkyBlue\">Create databrew IAM</p>\n",
    "- roles and policies that allow services to interact with other services\n",
    "- https://docs.aws.amazon.com/databrew/latest/dg/setting-up-iam-policies-for-databrew.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Move to the next cell ->\n"
     ]
    }
   ],
   "source": [
    "# myRoleDataBrew\n",
    "# trust policy for the role\n",
    "roleTrust = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\"Service\": \"databrew.amazonaws.com\"},\n",
    "            \"Action\": \"sts:AssumeRole\",\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "# define inline policy\n",
    "policyJson = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"logs:CreateLogGroup\",\n",
    "                \"logs:CreateLogStream\",\n",
    "                \"logs:PutLogEvents\",\n",
    "            ],\n",
    "            \"Resource\": \"*\",\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:PutObject\",\n",
    "                \"s3:DeleteObject\",\n",
    "                \"s3:ListBucket\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                f\"arn:aws:s3:::{myBucketCostOpt}\",\n",
    "                f\"arn:aws:s3:::{myBucketCostOpt}/*\"\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "# create inline policy\n",
    "policy = iam.create_policy(\n",
    "    PolicyName=myPolicyDataBrew,\n",
    "    PolicyDocument=json.dumps(policyJson),\n",
    "    Description=\"Policy for databrew\",\n",
    "    Tags=[\n",
    "        *myTags,\n",
    "    ],\n",
    ")\n",
    "\n",
    "# create role\n",
    "role = iam.create_role(\n",
    "    RoleName=myRoleDataBrew,\n",
    "    AssumeRolePolicyDocument=json.dumps(roleTrust),\n",
    "    Description=\"Role for databrew\",\n",
    "    Tags=[\n",
    "        *myTags,\n",
    "    ],\n",
    ")\n",
    "\n",
    "# attach inline policies to role\n",
    "response = iam.attach_role_policy(\n",
    "    RoleName=role[\"Role\"][\"RoleName\"], PolicyArn=policy[\"Policy\"][\"Arn\"]\n",
    ")\n",
    "\n",
    "myRoleDataBrewARN = role['Role']['Arn']\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:LightSkyBlue\">Create a dataset from our datasource</span>\n",
    "- We create datasets from the xl files we have uploaded into S3\n",
    "- We need to create a dataset before we can create anything else that uses it\n",
    "- https://docs.aws.amazon.com/databrew/latest/dg/datasets.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Move to the next cell ->\n"
     ]
    }
   ],
   "source": [
    "# dataset with pii\n",
    "response = databrew.create_dataset(\n",
    "    Name=myDataSet,\n",
    "    Format='CSV',\n",
    "    FormatOptions={\n",
    "        'Csv': {\n",
    "            'Delimiter': ',',\n",
    "            'HeaderRow': True\n",
    "        }\n",
    "    },\n",
    "    Input={\n",
    "        'S3InputDefinition': {\n",
    "            'Bucket': myBucketCostOpt,\n",
    "            'Key': '{}/{}'.format(myBucketFolder, filename),\n",
    "            'BucketOwner': myAccountNumber\n",
    "        }\n",
    "    },\n",
    "    Tags=myTagsDct,\n",
    ")\n",
    "\n",
    "# need to ARN which is only available if we describe it\n",
    "response = databrew.describe_dataset(\n",
    "    Name=myDataSet\n",
    ")\n",
    "myDataSetARN = response['ResourceArn']\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:LightSkyBlue\">Create a recipe</span>\n",
    "- create a simple recipe to perform transformations on our dataset\n",
    "- needed to be able to create a project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Move to the next cell ->\n"
     ]
    }
   ],
   "source": [
    "response = databrew.create_recipe(\n",
    "    Name=myRecipe,\n",
    "    Description=\"recipe 1 - to be used in a project\",\n",
    "    Steps=[\n",
    "        {\n",
    "            \"Action\": {\n",
    "                \"Operation\": \"UPPER_CASE\",\n",
    "                \"Parameters\": {\"sourceColumn\": \"bill_billing_entity\"},\n",
    "            }\n",
    "        },\n",
    "    ],\n",
    "    Tags=myTagsDct,\n",
    ")\n",
    "\n",
    "print(\"Done! Move to the next cell ->\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:LightSkyBlue\">Create a databrew project</span>\n",
    "- a project is a playground where you can experiment with recipes\n",
    "- it can use existing recipes, and review and update them\n",
    "- or you can create new recipes in a project, and publish them if production ready\n",
    "- once created, you can play with this project via the console\n",
    "- only samples the first 5000 rows - this is the max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Move to the next cell ->\n"
     ]
    }
   ],
   "source": [
    "response = databrew.create_project(\n",
    "    Name=myProject,\n",
    "    DatasetName=myDataSet,\n",
    "    RecipeName=myRecipe,\n",
    "    Sample={\n",
    "        'Size': 5000,\n",
    "        'Type': 'FIRST_N'\n",
    "    },\n",
    "    RoleArn=myRoleDataBrewARN,\n",
    "    Tags=myTagsDct,\n",
    ")\n",
    "\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now view the dataset in the databrew project if you wish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px dotted;color:LightSkyBlue\">\n",
    "<hr style=\"border:1px dotted;color:deeppink\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"color:deeppink\">STACK 01 COMPLETE!</p>\n",
    "- ### <p style=\"color:deeppink\">You can now invoke the lambda</p>\n",
    "- ### <p style=\"color:deeppink\">This will create a cost optimisation document in the bucket we have created!</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px dotted;color:deeppink\">\n",
    "<hr style=\"border:1px dotted;color:orangered\">\n",
    "<hr style=\"border:1px dotted;color:orangered\">\n",
    "<hr style=\"border:1px dotted;color:orangered\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"color:orangered\">CLEAN UP!!</p>\n",
    "# <p style=\"color:orangered\">DO NOT RUN THESE UNLESS YOU WANT TO DESTROY EVERYTHING</p>\n",
    "- If you have lost the Kernel:\n",
    "  - Run the cells contained in the <span style=\"color:greenyellow\">Set Up Requirements<span> section before continuing...\n",
    "  - Any IDs or ARNs will have to be manually stated\n",
    "### <p style=\"color:orangered\">Click on the Variables in the tool bar above to display all variables, you'll see those that may have no value if you have lost or stopped your kernel</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete databrew project\n",
    "try:\n",
    "    databrew.delete_project(Name=myProject)\n",
    "except Exception as err:\n",
    "    print(f'1:{err}')\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete recipes\n",
    "# if no further work has been done on these recipes via the console, this piece of code should delete all that is there\n",
    "# if not, either manually delete remaining recipes via the console or edit this code\n",
    "try:\n",
    "    databrew.delete_recipe_version(\n",
    "        Name=myRecipe,\n",
    "        RecipeVersion='LATEST_WORKING'\n",
    "    )\n",
    "except Exception as err:\n",
    "    print(f'1:{err}')\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete databrew dataset\n",
    "try:\n",
    "    databrew.delete_dataset(Name=myDataSet)\n",
    "except Exception as err:\n",
    "    print(f'1:{err}')\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambdas\n",
    "lambdac.delete_function(FunctionName=myLambda1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete lambda roles and policies\n",
    "try:\n",
    "    iam.detach_role_policy(\n",
    "        RoleName=myRoleLambda1, PolicyArn='arn:aws:iam::{}:policy/{}'.format(myAccountNumber, myPolicyLambda1)\n",
    "    )\n",
    "except Exception as err:\n",
    "    print(f'1:{err}')\n",
    "\n",
    "try:\n",
    "    iam.delete_role(RoleName=myRoleLambda1)\n",
    "except Exception as err:\n",
    "    print(f'4:{err}')\n",
    "\n",
    "try:\n",
    "    iam.delete_policy(PolicyArn='arn:aws:iam::{}:policy/{}'.format(myAccountNumber, myPolicyLambda1))\n",
    "except Exception as err:\n",
    "    print(f'5:{err}')\n",
    "\n",
    "# delete databrew roles and policies\n",
    "try:\n",
    "    iam.detach_role_policy(\n",
    "        RoleName=myRoleDataBrew, PolicyArn='arn:aws:iam::{}:policy/{}'.format(myAccountNumber, myPolicyDataBrew)\n",
    "    )\n",
    "except Exception as err:\n",
    "    print(f'1:{err}')\n",
    "\n",
    "try:\n",
    "    iam.delete_role(RoleName=myRoleDataBrew)\n",
    "except Exception as err:\n",
    "    print(f'4:{err}')\n",
    "\n",
    "try:\n",
    "    iam.delete_policy(PolicyArn='arn:aws:iam::{}:policy/{}'.format(myAccountNumber, myPolicyDataBrew))\n",
    "except Exception as err:\n",
    "    print(f'5:{err}')\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete s3 bucket\n",
    "# NOTE WARNING - this will delete all objects in the bucket with NO prompt or confirmation\n",
    "# myBucketCostOpt = 'doit-costopt-bucket-???-???' # look in the console and set here if lost\n",
    "try:\n",
    "    s3r = boto3.resource('s3')\n",
    "    bucket = s3r.Bucket(myBucketCostOpt)\n",
    "    bucket.objects.all().delete()\n",
    "except Exception as err:\n",
    "    print(f'9:{err}')\n",
    "\n",
    "try:\n",
    "    # delete the bucket\n",
    "    response = s3.delete_bucket(Bucket=myBucketCostOpt)\n",
    "except Exception as err:\n",
    "    print(f'9:{err}')\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px dotted;color:coral\">\n",
    "<hr style=\"border:1px dotted;color:coral\">\n",
    "<hr style=\"border:1px dotted;color:coral\">\n",
    "<hr style=\"border:1px dotted;color:gold\">\n",
    "<hr style=\"border:1px dotted;color:gold\">\n",
    "<hr style=\"border:1px dotted;color:gold\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"color:gold\">Appendix - Jupyter Install Requirements (macOS)</p>\n",
    "#### <p style=\"color:deeppink\">- If you are running VSCode on a laptop, follow all of below.<br>- If you are running Jupyter inside an AWS Account, you don't need to do anything!</p>\n",
    "\n",
    "  - Credentials to the AWS account this notebook executes in is provided by AWS configure\n",
    "  - You must already have an IAM user with code (Command Line Interface) access and AWS access keys to be able to use these credentials in AWS configure  \n",
    "    \n",
    "  - arn:aws:iam::###########:user/simon-davies-cli was created for this lab when the workshop was presented\n",
    "\n",
    "### <p style=\"color:gold\">1. Homebrew</p> \n",
    "If you haven't installed Homebrew, you can install it by running the following command here or in the terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "sudo /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"color:gold\">1.1 Virtual Environments</p> \n",
    "- You can create a virtual environment that ensures any libraries you install are restricted to the venv.\n",
    "  - https://code.visualstudio.com/docs/python/environments\n",
    "- To enable the virtual environment once you have created it, ensure you open the folder in vs code rather than individual files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "sudo /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"color:gold\">1.2 Python</p> \n",
    "Once Homebrew is installed, you can install Python using the following command  \n",
    "*check what you have before installing/upgrading*  \n",
    "*you will need to quit and restart vsCode to use python once installed (or updated)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "python3 --version\n",
    "which python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "brew install python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"color:gold\">2. boto3 and other Python requirements</p> \n",
    "* boto3 must be installed on your client\n",
    "  * *Boto3 is the Amazon Web Services (AWS) Software Development Kit (SDK) for Python, which allows Python developers to write software that makes use of services like Amazon S3 and Amazon EC2.*\n",
    "  * https://boto3.amazonaws.com/v1/documentation/api/latest/index.html  \n",
    "  \n",
    "*check what you have before installing/upgrading*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "python3 -m pip show boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install -U boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"color:gold\">3. aws configure</p> \n",
    "*Configure aws configure with credentials, and a user that has all of the Bedrock IAM policies required*  \n",
    "https://docs.aws.amazon.com/bedrock/latest/userguide/security_iam_id-based-policy-examples.html\n",
    "  \n",
    "*You will need AWS CLI*  \n",
    "https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-getting-started.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "aws sts get-caller-identity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px dotted;color:gold\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
