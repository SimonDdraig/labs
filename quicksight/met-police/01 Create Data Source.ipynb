{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"color:dodgerblue\">01 Create Data Source</p>\n",
    "*We will upload a datasource file which represents stop and search statistics performed by the London Metropolitan Police*  \n",
    "\n",
    "- this notebook creates the following:\n",
    "  - s3 bucket to:\n",
    "    - drop datasource files into \n",
    "    - used as resource for redshift\n",
    "  - iam\n",
    "    - roles\n",
    "    - policies\n",
    "  - redshift cluster\n",
    "    - model management\n",
    "    - security management\n",
    "  - secrets manager\n",
    "    - cluster and database secret credentials\n",
    "  - includes clean up cells to delete all above  \n",
    "  \n",
    "(At least Kernel 3.11.6 - venv if local)\n",
    "<hr style=\"border:1px dotted; color:floralwhite\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:deeppink\">GETTING STARTED</span>\n",
    "# Requirements for this Lab (macOS)\n",
    "- *See <span style=\"color:gold\">Appendix</span> at the bottom of this lab to install macOS requirements, windows requirements will be similar, apart from Homebrew.*  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px dotted\">\n",
    "<hr style=\"border:1px dotted;color:greenyellow\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"color:greenyellow\">Set Up Requirements</p>\n",
    "- we do these setup cells here because we can then use the vars and clients to clean up resources later without having to run multiple cells if we lose the kernel  \n",
    "  \n",
    "-  <span style=\"color:greenyellow\">Please note we use us-west-2 region as Q in QuickSight is not available worldwide yet<span>\n",
    "\n",
    "- vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import random\n",
    "\n",
    "# verify AWS account and store in myAccountNumber\n",
    "myAccountNumber = boto3.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "print('My account number: {}'.format(myAccountNumber))\n",
    "\n",
    "# region - we use us-west-2 as Q in QuickSight is limited in other reasons\n",
    "myRegion='us-west-2'\n",
    "myLabPrefix='doit-quicksight-london-met-'\n",
    "\n",
    "# bucket - MUST BE A UNIQUE NAME hence the random postfixes\n",
    "myBucket=myLabPrefix + 'bucket-' + str(random.randint(0, 1000)) + '-' + str(random.randint(0, 1000))\n",
    "\n",
    "# iam\n",
    "myRoleRedshift=myLabPrefix+'redshift-attached-role'\n",
    "myPolicyRedshift1=myLabPrefix + 'redshift-s3-policy'\n",
    "myPolicyRedshift2=myLabPrefix + 'redshift-secrets-policy'\n",
    "myPolicyRedshift3=myLabPrefix + '???'\n",
    "myPolicyRedshift4=myLabPrefix + '???'\n",
    "myRoleRedshiftARN='RETRIEVED BELOW ONCE CREATED'\n",
    "\n",
    "myRoleQuickSight=myLabPrefix + 'met-service-role'\n",
    "myPolicyQuickSight1=myLabPrefix + '??-policy'\n",
    "myRoleQuickSightARN='RETRIEVED BELOW ONCE CREATED'\n",
    "\n",
    "# Redshift\n",
    "myDBClusterIdentifier=myLabPrefix + 'cluster'\n",
    "myClusterHost='RETRIEVED BELOW ONCE CREATED'\n",
    "myClusterARN='RETRIEVED BELOW ONCE CREATED'\n",
    "myRedshiftDB=\"london-met\"\n",
    "myDBInstanceIdentifier=\"primary-instance\"\n",
    "mySecret4db=myLabPrefix + 'db-secret'\n",
    "mySecret4dbARN='RETRIEVED BELOW ONCE CREATED'\n",
    "mySecretRedshiftMasterARN='RETRIEVED BELOW ONCE CREATED'\n",
    "\n",
    "# network\n",
    "myVPC=myLabPrefix + 'redshift-vpc'\n",
    "mySGRedshift=myLabPrefix + 'redshift-sg'\n",
    "mySGQuickSight=myLabPrefix + 'quicksight-sg'\n",
    "\n",
    "# local client path for resources\n",
    "myLocalPathForDataSources='/Users/simondavies/Documents/GitHub/labs/quicksight/met-police/resources/datasource/'\n",
    "\n",
    "# jupypter notebook path for resources if notebook is used in AWS for example\n",
    "#myLocalPathForDataSources='/home/ec2-user/SageMaker/labs/quicksight/met-police/resources/datasource/'\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create required clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3\n",
    "s3 = boto3.client('s3', region_name=myRegion)\n",
    "\n",
    "# ec2 (reqd for networking services)\n",
    "ec2 = boto3.client('ec2', region_name=myRegion)\n",
    "\n",
    "# redshift\n",
    "redshift = boto3.client('redshift', region_name=myRegion)\n",
    "\n",
    "# quicksight\n",
    "quicksight = boto3.client('quicksight', region_name=myRegion)\n",
    "\n",
    "# iam\n",
    "iam = boto3.client('iam', region_name=myRegion)\n",
    "\n",
    "# secrets manager\n",
    "secrets = boto3.client('secretsmanager', region_name=myRegion)\n",
    "\n",
    "# logs (cloudwatch)\n",
    "logs = boto3.client('logs', region_name=myRegion)\n",
    "\n",
    "# cidr blocks\n",
    "vpcCIDR = \"10.0.0.0/24\"\n",
    "subnetaCIDR=\"10.0.0.0/25\"\n",
    "subnetbCIDR=\"10.0.0.128/25\"\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tags for all services that are created - you can never have too many tags!\n",
    "  - make sure you have a tagging policy in place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define tags added to all services we create\n",
    "myTags = [\n",
    "    {\"Key\": \"env\", \"Value\": \"non_prod\"},\n",
    "    {\"Key\": \"owner\", \"Value\": myLabPrefix + \"lab\"},\n",
    "    {\"Key\": \"project\", \"Value\": myLabPrefix + \"bi\"},\n",
    "    {\"Key\": \"author\", \"Value\": \"simon\"},\n",
    "]\n",
    "myTagsDct = {\n",
    "    \"env\": \"non_prod\",\n",
    "    \"owner\": myLabPrefix + \"lab\",\n",
    "    \"project\": myLabPrefix + \"bi\",\n",
    "    \"author\": \"simon\",\n",
    "}\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px dotted;color:greenyellow\">\n",
    "<hr style=\"border:1px dotted;color:crimson\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"color:crimson\">Create S3 Bucket</p>\n",
    "- defaults used, will use sse-s3 encryption and block public access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bucket\n",
    "s3.create_bucket(\n",
    "    Bucket=myBucket, CreateBucketConfiguration={\"LocationConstraint\": myRegion}\n",
    ")\n",
    "s3.put_bucket_tagging(Bucket=myBucket, Tagging={\"TagSet\": myTags})\n",
    "\n",
    "# create a \"folder\" - really keys as S3 is flat\n",
    "s3.put_object(Bucket=myBucket, Key=\"datasource/\")\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- upload resource files to s3 that will be used to create the knowledge base with\n",
    "  - includes metadata file\n",
    "  - https://docs.aws.amazon.com/bedrock/latest/userguide/knowledge-base-ds.html#kb-ds-metadata\n",
    "  - If you're adding metadata to a vector index in an Amazon Aurora database cluster, you must add a column to the table for each metadata attribute in your metadata files before starting ingestion. The metadata attribute values will be written to these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload each file to the S3 bucket\n",
    "files = [\n",
    "    {\n",
    "        's3key': 'datasource/Stops_LDS_Extract_24Months.csv',\n",
    "        'localpath': '{}Stops_LDS_Extract_24Months.csv'.format(myLocalPathForDataSources)\n",
    "    }\n",
    "]\n",
    "\n",
    "for file in files:\n",
    "    print ('uploading: {}'.format(file['s3key']))\n",
    "    s3.upload_file(file['localpath'], myBucket, file['s3key'], ExtraArgs={'StorageClass': 'STANDARD'})\n",
    "    print ('uploaded: {}'.format(file['s3key']))\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px dotted;color:crimson\">\n",
    "<hr style=\"border:1px dotted;color:ForestGreen\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"color:ForestGreen\">Create Network</p>\n",
    "- vpc  \n",
    "  - /24 is a reasonable size for a small VPC. This gives you 256 IPs, but note the following:\n",
    "  - The first 3 and last in the IP range is reserved by AWS\n",
    "  - VPC cidr blocks cannot overlap\n",
    "  - Each subnet in a vpc must have a netmask block between /28 (16 IPs) and /16 (65536 IPs)\n",
    "  - RDS typically requires at least 2 subnets if a standby or read replica is provisioned\n",
    "\n",
    "https://docs.aws.amazon.com/vpc/latest/userguide/vpc-cidr-blocks.html  \n",
    "https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_VPC.Scenarios.html  \n",
    "https://mxtoolbox.com/subnetcalculator.aspx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create redshift vpc\n",
    "vpc_redshift = ec2.create_vpc(\n",
    "    CidrBlock=vpcCIDR,\n",
    "    TagSpecifications=[\n",
    "        {\n",
    "            \"Tags\": [\n",
    "                *myTags,\n",
    "                {\"Key\": \"Name\", \"Value\": myVPC},\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2 private subnets\n",
    "  - We'll break the /24 of the VPC over 2 subnets of /25 each\n",
    "  - The first 4 and last in the IP range is reserved by AWS\n",
    "  - Subnet cidr blocks cannot overlap\n",
    "  - RDS typically requires 3 subnets\n",
    "\n",
    "https://docs.aws.amazon.com/vpc/latest/userguide/subnet-sizing.html\n",
    "https://mxtoolbox.com/subnetcalculator.aspx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vpc-redshift subnets\n",
    "subnet_a_redshift = ec2.create_subnet(\n",
    "    CidrBlock=subnetaCIDR,\n",
    "    AvailabilityZone=myRegion + \"a\",\n",
    "    VpcId=vpc_redshift[\"Vpc\"][\"VpcId\"],\n",
    "    TagSpecifications=[\n",
    "        {\n",
    "            \"Tags\": [\n",
    "                *myTags,\n",
    "                {\"Key\": \"Name\", \"Value\": myVPC + \"-subnet-a\"},\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "subnet_b_redshift = ec2.create_subnet(\n",
    "    CidrBlock=subnetbCIDR,\n",
    "    AvailabilityZone=myRegion + \"b\",\n",
    "    VpcId=vpc_redshift[\"Vpc\"][\"VpcId\"],\n",
    "    TagSpecifications=[\n",
    "        {\n",
    "            \"Tags\": [\n",
    "                *myTags,\n",
    "                {\"Key\": \"Name\", \"Value\": myVPC + \"-subnet-b\"},\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- redshift security group\n",
    "  - we need to create this now as we can reference its arn in the inbound and outbound rules of the quicksight sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create redshift security group\n",
    "sg_redshift = ec2.create_security_group(\n",
    "    GroupName=mySGRedshift,\n",
    "    Description=\"sg to allow quicksight ingress and egress to redshift\",\n",
    "    VpcId=vpc_redshift[\"Vpc\"][\"VpcId\"],\n",
    "    TagSpecifications=[\n",
    "        {\n",
    "            \"Tags\": [\n",
    "                *myTags,\n",
    "                {\"Key\": \"Name\", \"Value\": mySGRedshift},\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- quicksight security group\n",
    "  - we need to create this now as we can reference its arn in the inbound and outbound rules of the redshift sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create quicksight security group\n",
    "sg_quicksight = ec2.create_security_group(\n",
    "    GroupName=mySGQuickSight,\n",
    "    Description=\"sg to allow redshift ingress and egress to quicksight\",\n",
    "    VpcId=vpc_redshift[\"Vpc\"][\"VpcId\"],\n",
    "    TagSpecifications=[\n",
    "        {\n",
    "            \"Tags\": [\n",
    "                *myTags,\n",
    "                {\"Key\": \"Name\", \"Value\": mySGQuickSight},\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- rules for redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create inbound rule allowing quicksight to reach redshift\n",
    "ec2.authorize_security_group_ingress(\n",
    "    GroupId=sg_redshift[\"GroupId\"],\n",
    "    IpPermissions=[\n",
    "        {\n",
    "            \"FromPort\": 5439,\n",
    "            \"ToPort\": 5439,\n",
    "            \"IpProtocol\": \"tcp\",\n",
    "            'UserIdGroupPairs': [\n",
    "                {\n",
    "                    'Description': 'allows quicksight to reach redshift',\n",
    "                    'GroupId': sg_quicksight[\"GroupId\"],\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "# create outbound rule allowing redshift to reach quicksight\n",
    "ec2.authorize_security_group_egress(\n",
    "    GroupId=sg_redshift[\"GroupId\"],\n",
    "    IpPermissions=[\n",
    "        {\n",
    "            \"FromPort\": 0,\n",
    "            \"ToPort\": 65535,\n",
    "            \"IpProtocol\": \"tcp\",\n",
    "            'UserIdGroupPairs': [\n",
    "                {\n",
    "                    'Description': 'allows redshift to reach quicksight',\n",
    "                    'GroupId': sg_quicksight[\"GroupId\"],\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px dotted;color:ForestGreen\">\n",
    "<hr style=\"border:1px dotted;color:lightskyblue\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"color:LightSkyBlue\">Create Redshift Cluster</p>\n",
    "- redshift cluster\n",
    "  - we create a private master node with 2 data nodes\n",
    "  - we use a single az (multi az does not support dc2)\n",
    "  - best practice is multi az with a master node and a number of compute nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a dc2.large here as we have very small, static datasets\n",
    "# if you have larger datasets, expect regular growth, you can change the instance type to something more suitable\n",
    "# eg ra3 which separates storage and compute for better scaling\n",
    "redshift_cluster = redshift.create_cluster(\n",
    "    ClusterIdentifier=myDBClusterIdentifier,\n",
    "    DBName=myRedshiftDB,\n",
    "    NodeType='dc2.large',\n",
    "    MasterUsername='masteruser',\n",
    "    ManageMasterPassword=True,\n",
    "    ClusterSubnetGroupName='my-subnet-group',\n",
    "    ClusterSecurityGroups=['my-security-group'],\n",
    "    ClusterType='multi-node',\n",
    "    NumberOfNodes=2,\n",
    "    PubliclyAccessible=False,\n",
    "    Encrypted=True,\n",
    "    IamRoles=[myRoleRedshiftARN],\n",
    "    LoadSampleData=False,\n",
    "    Tags=[\n",
    "        *myTags,\n",
    "        {\"Key\": \"Name\", \"Value\": \"{}\".format(myDBClusterIdentifier)},\n",
    "    ],\n",
    ")\n",
    "\n",
    "# grab the secrets manager secret arn\n",
    "mySecretRedshiftMasterARN=redshift_cluster['Cluster']['MasterPasswordSecretArn']\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the Secrets Manager masteruser secret ARN, we can use this later to login via the AWS Console Query Editor\n",
    "print(mySecretRedshiftMasterARN)\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Wait for the cluster to finish creating\n",
    "  - cant create an instance until the cluster is ready\n",
    "#### <span style=\"color:deeppink\">you can run the following cell multiple times until the status is available and active</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can take approx 2 mins to create the cluster\n",
    "cluster=rds.describe_db_clusters(DBClusterIdentifier=myDBClusterIdentifier)['DBClusters'][0]\n",
    "print(cluster['Status'])\n",
    "print(cluster['MasterUserSecret']['SecretStatus'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create aurora instance\n",
    "  - Aurora Optimized Reads on Amazon EC2 R6gd and R6id instances use local storage to enhance read performance and throughput for complex queries and index rebuild operations\n",
    "  - With vector workloads that donâ€™t fit into memory, Aurora Optimized Reads can offer up to 9x better query performance over Aurora instances of the same size\n",
    "  - https://aws.amazon.com/blogs/aws/knowledge-bases-for-amazon-bedrock-now-supports-amazon-aurora-postgresql-and-cohere-embedding-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the host and arn of the cluster - we need for secrets and kb later\n",
    "myClusterHost = rds_cluster[\"DBCluster\"][\"Endpoint\"]\n",
    "myClusterARN = rds_cluster[\"DBCluster\"][\"DBClusterArn\"]\n",
    "\n",
    "# create rds aurora instance\n",
    "rds_instance = rds.create_db_instance(\n",
    "    DBInstanceIdentifier=myDBInstanceIdentifier,\n",
    "    DBClusterIdentifier=rds_cluster[\"DBCluster\"][\"DBClusterIdentifier\"],\n",
    "    DBInstanceClass=\"db.r6g.large\",\n",
    "    Engine=\"aurora-postgresql\",\n",
    "    AvailabilityZone=\"{}a\".format(myRegion),\n",
    "    MultiAZ=False,\n",
    "    PubliclyAccessible=False,\n",
    "    Tags=[\n",
    "        *myTags,\n",
    "        {\"Key\": \"Name\", \"Value\": myDBInstanceIdentifier},\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Wait for the instance to finish creating\n",
    "#### <span style=\"color:deeppink\">you can run the following cell multiple times until the status is available</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can take approx 10 mins to create the instance\n",
    "instance=rds.describe_db_instances(DBInstanceIdentifier=myDBInstanceIdentifier)['DBInstances'][0]\n",
    "print(instance['DBInstanceStatus'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- configure aurora postgres so it can be a vector database\n",
    "  - install extensions\n",
    "    - https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraPostgreSQL.VectorDB.html  \n",
    "  - create required knowledge base objects in the aurora database\n",
    "    - https://docs.aws.amazon.com/bedrock/latest/userguide/knowledge-base-setup.html  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the Secrets Manager masteruser secret ARN, we need these credentials to login to the AWS RDS Query Editor\n",
    "mySecretRedshiftMasterARN, myRedshiftDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"color:LightSkyBlue\">Query Editor Part 1</p>\n",
    "- From your AWS Console\n",
    "  - Go to RDS service\n",
    "  - In left hand panel, select Databases\n",
    "    - Check your database is there\n",
    "  - On left hand panel, select Query Editor\n",
    "    - Select the database just created\n",
    "    - Database username - Connect with a Secrets Manager ARN\n",
    "      - use credentials from above cell\n",
    "  - Paste each SQL statement into the Query Editor and run each one individually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:deeppink\">DO NOT RUN THESE CELLS, COPY AND PASTE EACH SQL INTO QUERY EDITOR</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- connect to your database with master user (stored in secrets manager when aurora cluster was created) \n",
    "-- using the Query Editor (and Secrets Manager ARN) in the AWS console\n",
    "-- see secret arn and database name in above cell\n",
    "-- ... execute the following sql\n",
    "\n",
    "-- code to execute in the database\n",
    "-- NOTE if you see an error like \"Create query history error\", please ignore, as long as your query output shows \"success\" you're ok\n",
    "\n",
    "-- *** LOGIN WITH MASTER USER ***\n",
    "\n",
    "-- 1. setup pgvector\n",
    "CREATE EXTENSION IF NOT EXISTS vector;\n",
    "\n",
    "-- 2. check the version\n",
    "SELECT extversion FROM pg_extension WHERE extname='vector';\n",
    "\n",
    "-- 3. schema that Bedrock can use to query the data\n",
    "CREATE SCHEMA bedrock_integration;\n",
    "\n",
    "-- 4. role that Bedrock can use to query the database\n",
    "-- make a note of this password as you would be using the same to create a Secrets Manager password\n",
    "-- OBVIOUSLY in your infra as code: obfiscate any password, use a random uuid, encrypt, source from a file, or manually change\n",
    "CREATE ROLE bedrock_user WITH PASSWORD 'do-n0t-hardcode-m3!' LOGIN;\n",
    "\n",
    "-- 5. grant the bedrock_user permission to manage the bedrock_integration schema\n",
    "GRANT ALL ON SCHEMA bedrock_integration to bedrock_user;\n",
    "\n",
    "-- now create an AWS Secrets Manager database secret for the user just created\n",
    "-- back to Jupyter!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create secrets manager secret linked to RDS for the user in the db just created\n",
    "  - https://docs.aws.amazon.com/secretsmanager/latest/userguide/create_database_secret.html\n",
    "  - https://docs.aws.amazon.com/secretsmanager/latest/userguide/reference_secret_json_structure.html#reference_secret_json_structure_rds-postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBVIOUSLY in your infra as code: obfiscate any password, use a random uuid, encrypt, source from a file, or manually change\n",
    "secretString = {\"engine\": \"postgres\", \\\n",
    "                    \"host\": myClusterHost, \\\n",
    "                    \"dbClusterIdentifier\" : myDBClusterIdentifier, \\\n",
    "                    \"username\": \"bedrock_user\", \\\n",
    "                    \"password\": \"do-n0t-hardcode-m3!\", \\\n",
    "                    \"dbname\": myRedshiftDB, \\\n",
    "                    \"port\": 5432 \\\n",
    "                    }\n",
    "\n",
    "response = secrets.create_secret(\n",
    "    Name=mySecret4db,\n",
    "    Description=\"stores the credential for the vector db created in the {} of the aurora cluster for bedrock\".format(myDBInstanceIdentifier),\n",
    "    SecretString=json.dumps(secretString),\n",
    "    Tags=[\n",
    "        *myTags,\n",
    "        {\"Key\": \"Name\", \"Value\": mySecret4db},\n",
    "    ],\n",
    ")\n",
    "\n",
    "mySecret4dbARN = response['ARN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- finish off the sql object requirements in the database using the user just created\n",
    "  - If you're adding metadata to a vector index in an Amazon Aurora database cluster, you must add a column to the table for each metadata attribute in your metadata files before starting ingestion. The metadata attribute values will be written to these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the Secrets Manager db bedrock user secret ARN, we need this to login \n",
    "mySecret4dbARN, myRedshiftDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"color:LightSkyBlue\">Query Editor Part 2</p>\n",
    "- From your AWS Console\n",
    "  - Go to RDS service\n",
    "  - If you are still using the Query Editor, click Change Database\n",
    "   - On left hand panel, select Query Editor\n",
    "    - Select the database just created\n",
    "    - Database username - Connect with a Secrets Manager ARN\n",
    "      - use credentials from above cell\n",
    "  - Paste each SQL statement into the Query Editor and run each one individually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:deeppink\">DO NOT RUN THESE CELLS, COPY AND PASTE EACH SQL INTO QUERY EDITOR</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- *** LOGOUT OF THE QUERY EDITOR IF STILL LOGGED IN ***\n",
    "-- *** CLICK CHANGE DATABASE TO LOGOUT ***\n",
    "-- *** LOGIN WITH BEDROCK_USER JUST CREATED ***\n",
    "-- see secret arn and database name in above cell\n",
    "\n",
    "-- 1. create a table in the bedrock_integration schema\n",
    "CREATE TABLE bedrock_integration.bedrock_kb (id uuid PRIMARY KEY, embedding vector(1536), chunks text, metadata json, country varchar(30), category varchar(30));\n",
    "\n",
    "-- 2. create an index with the cosine operator which the bedrock can use to query the data\n",
    "CREATE INDEX on bedrock_integration.bedrock_kb USING hnsw (embedding vector_cosine_ops);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can now close the Query Editor if you wish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px dotted;color:lightskyblue\">\n",
    "<hr style=\"border:1px dotted;color:orchid\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"color:orchid\">Create IAM</p>\n",
    "- roles and policies for the services to interact with other services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- bedrock iam\n",
    "  - https://docs.aws.amazon.com/bedrock/latest/userguide/kb-permissions.html#kb-permissions-rds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define kb-fm-model-policy json\n",
    "policyJson = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"bedrock:ListFoundationModels\",\n",
    "                \"bedrock:ListCustomModels\"\n",
    "            ],\n",
    "            \"Resource\": \"*\"\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"bedrock:InvokeModel\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:bedrock:{}::foundation-model/{}\".format(myRegion, myEmbeddingModel)\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# create kb-fm-model-policy policy\n",
    "policy1 = iam.create_policy(\n",
    "    PolicyName=myPolicyRedshift1,\n",
    "    PolicyDocument=json.dumps(policyJson),\n",
    "    Description=\"Policy allowing Bedrock KB to use the specified foundation model\",\n",
    "    Tags=[\n",
    "        *myTags,\n",
    "    ],\n",
    ")\n",
    "\n",
    "# define kb-s3-policy json\n",
    "policyJson = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3:ListBucket\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::{}\".format(myBucket)\n",
    "            ],\n",
    "            \"Condition\": {\n",
    "                \"StringEquals\": {\n",
    "                    \"aws:ResourceAccount\": \"{}\".format(myAccountNumber)\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3:GetObject\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::{}/*\".format(myBucket)\n",
    "            ],\n",
    "            \"Condition\": {\n",
    "                \"StringEquals\": {\n",
    "                    \"aws:ResourceAccount\": \"{}\".format(myAccountNumber)\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# create kb-s3-policy policy\n",
    "policy2 = iam.create_policy(\n",
    "    PolicyName=myPolicyRedshift2,\n",
    "    PolicyDocument=json.dumps(policyJson),\n",
    "    Description=\"Policy allowing Bedrock KB to use s3\",\n",
    "    Tags=[\n",
    "        *myTags,\n",
    "    ],\n",
    ")\n",
    "\n",
    "# define kb-aurora-policy json - a different vector database will need a different policy\n",
    "policyJson = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"rds:DescribeDBClusters\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:rds:{}:{}:cluster:{}\".format(myRegion, myAccountNumber, myDBClusterIdentifier)\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"rds-data:BatchExecuteStatement\",\n",
    "                \"rds-data:ExecuteStatement\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:rds:{}:{}:cluster:{}\".format(myRegion, myAccountNumber, myDBClusterIdentifier)\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# create kb-aurora-policy policy\n",
    "policy3 = iam.create_policy(\n",
    "    PolicyName=myPolicyRedshift3,\n",
    "    PolicyDocument=json.dumps(policyJson),\n",
    "    Description=\"Policy allowing Bedrock KB to use aurora as its vector database\",\n",
    "    Tags=[\n",
    "        *myTags,\n",
    "    ],\n",
    ")\n",
    "\n",
    "# define kb-secrets-policy json\n",
    "policyJson = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "            {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"secretsmanager:GetSecretValue\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                mySecret4dbARN\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# create kb-secrets-policy policy\n",
    "policy4 = iam.create_policy(\n",
    "    PolicyName=myPolicyRedshift4,\n",
    "    PolicyDocument=json.dumps(policyJson),\n",
    "    Description=\"Policy allowing Bedrock KB to access secrets manager for aurora credentials\",\n",
    "    Tags=[\n",
    "        *myTags,\n",
    "    ],\n",
    ")\n",
    "\n",
    "# trust policy for the role\n",
    "roleTrust = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\"Service\": \"bedrock.amazonaws.com\"},\n",
    "            \"Action\": \"sts:AssumeRole\",\n",
    "            \"Condition\": {\n",
    "                \"StringEquals\": {\n",
    "                    \"aws:SourceAccount\": \"{}\".format(myAccountNumber)\n",
    "                },\n",
    "                \"ArnLike\": {\n",
    "                    \"aws:SourceArn\": \"arn:aws:bedrock:{}:{}:knowledge-base/*\".format(myRegion, myAccountNumber)\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "# create role\n",
    "role = iam.create_role(\n",
    "    RoleName=myRoleRedshift,\n",
    "    AssumeRolePolicyDocument=json.dumps(roleTrust),\n",
    "    Description=\"Service role for Bedrock Knowledge Base use\",\n",
    "    Tags=[\n",
    "        *myTags,\n",
    "    ],\n",
    ")\n",
    "\n",
    "# attach policies to role\n",
    "iam.attach_role_policy(\n",
    "    RoleName=role[\"Role\"][\"RoleName\"], PolicyArn=policy1[\"Policy\"][\"Arn\"]\n",
    ")\n",
    "\n",
    "iam.attach_role_policy(\n",
    "    RoleName=role[\"Role\"][\"RoleName\"], PolicyArn=policy2[\"Policy\"][\"Arn\"]\n",
    ")\n",
    "\n",
    "iam.attach_role_policy(\n",
    "    RoleName=role[\"Role\"][\"RoleName\"], PolicyArn=policy3[\"Policy\"][\"Arn\"]\n",
    ")\n",
    "\n",
    "iam.attach_role_policy(\n",
    "    RoleName=role[\"Role\"][\"RoleName\"], PolicyArn=policy4[\"Policy\"][\"Arn\"]\n",
    ")\n",
    "\n",
    "myRoleRedshiftARN = role['Role']['Arn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px dotted;color:orchid\">\n",
    "<hr style=\"border:1px dotted;color:DarkSeaGreen\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"color:DarkSeaGreen\">Create Knowledge Base</p>\n",
    "Create the knowledge base\n",
    "* find embedding model arn\n",
    "* find model to use for kb generated responses\n",
    "* create iam role\n",
    "* create opensearch serverless cluster\n",
    "* create knowledge base\n",
    "* sync"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- find an embedding model to use - this will be used to create the kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the arn of the embedding model we need (this model converts your data into vectors)\n",
    "# We will be using Titan Embeddings G1 - Text v1.2 (Command Cohere is also available as an embedding model for KBs)\n",
    "# look in the list to get the ARN of the model we want to use\n",
    "# use in the bedrockKB.create_knowledge_base if we create the kb via code\n",
    "\n",
    "# this lists all models based on the filter\n",
    "response = bedrockChk.list_foundation_models(\n",
    "    byProvider='Amazon',\n",
    "    byOutputModality='EMBEDDING',\n",
    "    byInferenceType='PROVISIONED'\n",
    ")\n",
    "response\n",
    "\n",
    "# but we know what we want so lets just find it so we can get the arn\n",
    "response = bedrockChk.get_foundation_model(modelIdentifier=myEmbeddingModel)\n",
    "myEmbeddingModelARN=response['modelDetails']['modelArn']\n",
    "myEmbeddingModelARN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- find a foundation model to use - this will be used when we want to query the kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the arn of the model to use for kb generated responses (parses the data retrieved fropm the knowledge base)\n",
    "# Anthropic - Claude 2 V2\n",
    "# Claude also supports the Thai language\n",
    "# look in the list to get the ARN of the model we want to use\n",
    "# use in the bedrockKBRun.retrieve_and_generate when you query the kb\n",
    "\n",
    "# this lists all models based on the filter\n",
    "response = bedrockChk.list_foundation_models(\n",
    "    byProvider='Anthropic',\n",
    "    byOutputModality='TEXT',\n",
    "    byInferenceType='ON_DEMAND'\n",
    ")\n",
    "response\n",
    "\n",
    "# but we know what we want so lets just find it so we can get the arn\n",
    "response = bedrockChk.get_foundation_model(modelIdentifier=myQueryingModel)\n",
    "myQueryingModelARN=response['modelDetails']['modelArn']\n",
    "myQueryingModelARN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create the knowledge base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.aws.amazon.com/bedrock/latest/APIReference/API_agent_CreateKnowledgeBase.html\n",
    "# knowledge base with rds aurora postgres as the vector db\n",
    "response=bedrockKB.create_knowledge_base(\n",
    "    name=myKB,\n",
    "    description='Contains recipes and other food related information for Thai, Japanese and Italian dishes.',\n",
    "    roleArn=myRoleRedshiftARN,\n",
    "    knowledgeBaseConfiguration={\n",
    "        'type': 'VECTOR',\n",
    "        'vectorKnowledgeBaseConfiguration': {\n",
    "            'embeddingModelArn': myEmbeddingModelARN\n",
    "        }\n",
    "    },\n",
    "    storageConfiguration={\n",
    "        'type': 'RDS',\n",
    "        'rdsConfiguration': {\n",
    "            'credentialsSecretArn': mySecret4dbARN,\n",
    "            'databaseName': myVectorDB,\n",
    "            'fieldMapping': {\n",
    "                'metadataField': 'metadata',\n",
    "                'primaryKeyField': 'id',\n",
    "                'textField': 'chunks',\n",
    "                'vectorField': 'embedding'\n",
    "            },\n",
    "            'resourceArn': myClusterARN,\n",
    "            'tableName': 'bedrock_integration.bedrock_kb'\n",
    "        },\n",
    "    },\n",
    "    tags=myTagsDct,\n",
    ")\n",
    "\n",
    "myKBid=response['knowledgeBase']['knowledgeBaseId']\n",
    "myKBid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- wait for the kb to finish creating\n",
    "#### <span style=\"color:deeppink\">you can run the following cell multiple times until the status is ACTIVE</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can take approx 1 mins to create the kb\n",
    "print(bedrockKB.get_knowledge_base(knowledgeBaseId=myKBid)['knowledgeBase']['status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- add a datasource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the s3 bucket as a data source\n",
    "response=bedrockKB.create_data_source(\n",
    "    dataSourceConfiguration={\n",
    "        's3Configuration': {\n",
    "            'bucketArn': 'arn:aws:s3:::{}'.format(myBucket),\n",
    "            'inclusionPrefixes': [\n",
    "                'recipes',\n",
    "            ]\n",
    "        },\n",
    "        'type': 'S3'\n",
    "    },\n",
    "    description='Contains recipes and other food related information for Thai, Japanese and Italian dishes.',\n",
    "    knowledgeBaseId=myKBid,\n",
    "    name=myKBdatasource,\n",
    "    vectorIngestionConfiguration={\n",
    "        'chunkingConfiguration': {\n",
    "            'chunkingStrategy': 'FIXED_SIZE',\n",
    "            'fixedSizeChunkingConfiguration': {\n",
    "                'maxTokens': 300,\n",
    "                'overlapPercentage': 20\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "myDatasourceId=response['dataSource']['dataSourceId']\n",
    "myDatasourceId"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- wait for the data source to finish creating and synching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- wait for the kb to finish creating\n",
    "#### <span style=\"color:deeppink\">you can run the following cell multiple times until the status is AVAILABLE</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can take approx 1 mins to create the kb datasource\n",
    "print(bedrockKB.get_data_source(dataSourceId=myDatasourceId, knowledgeBaseId=myKBid)['dataSource']['status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- now sync the data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bedrockKB.start_ingestion_job(\n",
    "    dataSourceId=myDatasourceId,\n",
    "    knowledgeBaseId=myKBid,\n",
    "    description='Synching recipes and other food related information for Thai, Japanese and Italian dishes.'\n",
    ")\n",
    "\n",
    "myIngestionJobId=response['ingestionJob']['ingestionJobId']\n",
    "myIngestionJobId"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- wait for the data source to finish synching\n",
    "#### <span style=\"color:deeppink\">you can run the following cell multiple times until the status is COMPLETE</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can take up to 20 mins to sync the data source to the kb\n",
    "response = bedrockKB.get_ingestion_job(dataSourceId=myDatasourceId, ingestionJobId=myIngestionJobId, knowledgeBaseId=myKBid)\n",
    "\n",
    "print(response['ingestionJob']['startedAt'])\n",
    "print(response['ingestionJob']['status'])\n",
    "print('Statistics: {}'.format(response['ingestionJob']['statistics']))\n",
    "try:\n",
    "    print('Any failures: {}'.format(response['ingestionJob']['failureReasons']))\n",
    "except:\n",
    "    print('No failures')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px dotted;color:DarkSeaGreen\">\n",
    "<hr style=\"border:1px dotted;color:deeppink\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"color:deeppink\">STACK 01 COMPLETE!</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"color:deeppink\">Example Use of Knowledge Base</p>\n",
    "- the following code can be used in your projects to invoke the knowledge base we just created  \n",
    "<br>\n",
    "*You are able to query the knowledge base in the following ways*\n",
    "1. Retrieve - query a knowledge base and only return relevant text from data sources.\n",
    "2. RetrieveAndGenerate - query a knowledge base and use a foundation model to generate responses based off the results from the data sources.  \n",
    "https://docs.aws.amazon.com/bedrock/latest/userguide/knowledge-base-api-query.html#w116aac45c37c35c11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start querying!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE good examples of use of the KB\n",
    "promptkb='Give me a Thai recipe I can make for dinner thats quick and easy to prepare.'\n",
    "#promptkb='Tell me about fruits that are popular in Thailand. Include what fruits are available for each of the seasons.'\n",
    "#promptkb='What are the ingredients for Pork with Green Peppers, and how do I make it?'\n",
    "#promptkb='What Italian recipes do you have?'\n",
    "#promptkb='What is the best recipe for an Italian pizza base dough?'\n",
    "\n",
    "response = bedrockKBRun.retrieve_and_generate(\n",
    "    input={\n",
    "        'text': promptkb,\n",
    "    },\n",
    "    retrieveAndGenerateConfiguration={\n",
    "        'type': 'KNOWLEDGE_BASE',\n",
    "        'knowledgeBaseConfiguration': {\n",
    "            'knowledgeBaseId': myKBid,\n",
    "            'modelArn': myQueryingModelARN\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"GENERATED RESPONSE:\\n{}\".format(response['output']['text']))\n",
    "print(\"---------------------------------------\\n\")\n",
    "\n",
    "# A list of segments of the generated response that are based on sources in the knowledge base\n",
    "numCitations=len(response.get('citations'))\n",
    "print(\"NUMBER OF CITATIONS: {}\".format(numCitations))\n",
    "print(\"---------------------------------------\\n\")\n",
    "\n",
    "ic=0\n",
    "while ic <= numCitations-1:\n",
    "    print(\"CITATION: {}\".format(ic+1))\n",
    "    print(\"---------------------------------------\")\n",
    "\n",
    "    numReferences = len(response['citations'][ic].get('retrievedReferences'))\n",
    "    print(\"   NUMBER OF REFERENCES FOR CITATION {}: {}\".format(ic+1, numReferences))\n",
    "    print(\"   ---------------------------------------\")\n",
    "\n",
    "    print(\"   GENERATED TEXT: {}\".format(response['citations'][ic]['generatedResponsePart']['textResponsePart']['text']))\n",
    "    print(\"   ---------------------------------------\")\n",
    "\n",
    "    ir=0\n",
    "    while ir <= numReferences-1:\n",
    "        print(\"   REFERENCE: {}\".format(ir+1))\n",
    "        print(\"   ---------------------------------------\")\n",
    "\n",
    "        # reference ceted text used\n",
    "        print(\"      CITED TEXT: {}\".format(response['citations'][ic]['retrievedReferences'][ir]['content']))\n",
    "        print(\"      ---------------------------------------\")\n",
    "\n",
    "        # json metadata used as a filter\n",
    "        print(\"      METADATA USED: {}\".format(response['citations'][ic]['retrievedReferences'][ir]['metadata']))\n",
    "        print(\"      ---------------------------------------\")\n",
    "\n",
    "        # fata source s3 file\n",
    "        print(\"      S3 FILE: {}\".format(response['citations'][ic]['retrievedReferences'][ir]['location']))\n",
    "        print(\"      ---------------------------------------\")\n",
    "\n",
    "        ir +=1\n",
    "\n",
    "    ic +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px dotted;color:deeppink\">\n",
    "<hr style=\"border:1px dotted;color:orangered\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"color:orangered\">Clean Up - DO NOT DO THIS IN THIS LAB!!!!!</p>\n",
    "# <p style=\"color:orangered\">DO NOT RUN THESE UNLESS YOU WANT TO DESTROY EVERYTHING</p>\n",
    "- If you have lost the Kernel, run the cells contained in the <span style=\"color:greenyellow\">Set Up Requirements<span> section before the cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE if you have lost the kernel, you will need to manually get the dataSourceId and knowledgeBaseId\n",
    "myKBid='???'\n",
    "myDatasourceId='???'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete knowledge base data source\n",
    "bedrockKB.delete_data_source(\n",
    "    dataSourceId=myDatasourceId,\n",
    "    knowledgeBaseId=myKBid\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete knowledge base\n",
    "bedrockKB.delete_knowledge_base(\n",
    "    knowledgeBaseId=myKBid\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Wait for the kb to finish deleting\n",
    "  - cant delete dependencies until finished\n",
    "#### <span style=\"color:deeppink\">you can run the following cell multiple times until the status is Deleted</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can take approx 1 mins to delete the kb\n",
    "try:\n",
    "    print(bedrockKB.get_knowledge_base(knowledgeBaseId=myKBid)['knowledgeBase']['status'])\n",
    "except:\n",
    "    print(\"Deleted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete rds instance\n",
    "rds.delete_db_instance(\n",
    "    DBInstanceIdentifier=myDBInstanceIdentifier,\n",
    "    SkipFinalSnapshot=True,\n",
    "    DeleteAutomatedBackups=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Wait for the instance to finish deleting\n",
    "  - cant delete dependencies until finished\n",
    "#### <span style=\"color:deeppink\">you can run the following cell multiple times until the status is Deleted</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can take approx 10 mins to delete the instance\n",
    "try:\n",
    "    instance=rds.describe_db_instances(DBInstanceIdentifier=myDBInstanceIdentifier)['DBInstances'][0]\n",
    "    print(instance['DBInstanceStatus'])\n",
    "except:\n",
    "    print(\"Deleted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete rds cluster\n",
    "rds.delete_db_cluster(\n",
    "    DBClusterIdentifier=myDBClusterIdentifier,\n",
    "    SkipFinalSnapshot=True,\n",
    "    DeleteAutomatedBackups=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Wait for the cluster to finish deleting\n",
    "  - cant delete dependencies until finished\n",
    "#### <span style=\"color:deeppink\">you can run the following cell multiple times until the status is Deleted</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can take approx 10 mins to delete the cluster\n",
    "try:\n",
    "    cluster=rds.describe_db_clusters(DBClusterIdentifier=myDBClusterIdentifier)['DBClusters'][0]\n",
    "    print(cluster['Status'])\n",
    "    print(cluster['MasterUserSecret']['SecretStatus'])\n",
    "except:\n",
    "    print(\"Deleted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete secrets manager\n",
    "secrets.delete_secret(\n",
    "    SecretId=mySecret4db, \n",
    "    ForceDeleteWithoutRecovery=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete roles and policies\n",
    "iam.detach_role_policy(\n",
    "    RoleName=myRoleRedshift, PolicyArn='arn:aws:iam::{}:policy/{}'.format(myAccountNumber, myPolicyRedshift1)\n",
    ")\n",
    "iam.detach_role_policy(\n",
    "    RoleName=myRoleRedshift, PolicyArn='arn:aws:iam::{}:policy/{}'.format(myAccountNumber, myPolicyRedshift2)\n",
    ")\n",
    "iam.detach_role_policy(\n",
    "    RoleName=myRoleRedshift, PolicyArn='arn:aws:iam::{}:policy/{}'.format(myAccountNumber, myPolicyRedshift3)\n",
    ")\n",
    "iam.detach_role_policy(\n",
    "    RoleName=myRoleRedshift, PolicyArn='arn:aws:iam::{}:policy/{}'.format(myAccountNumber, myPolicyRedshift4)\n",
    ")\n",
    "\n",
    "iam.delete_role(RoleName=myRoleRedshift)\n",
    "iam.delete_policy(PolicyArn='arn:aws:iam::{}:policy/{}'.format(myAccountNumber, myPolicyRedshift1))\n",
    "iam.delete_policy(PolicyArn='arn:aws:iam::{}:policy/{}'.format(myAccountNumber, myPolicyRedshift2))\n",
    "iam.delete_policy(PolicyArn='arn:aws:iam::{}:policy/{}'.format(myAccountNumber, myPolicyRedshift3))\n",
    "iam.delete_policy(PolicyArn='arn:aws:iam::{}:policy/{}'.format(myAccountNumber, myPolicyRedshift4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete s3 bucket\n",
    "# NOTE WARNING - this will delete all objects in the bucket with NO prompt or confirmation\n",
    "s3r = boto3.resource('s3')\n",
    "bucket = s3r.Bucket(myBucket)\n",
    "bucket.objects.all().delete()\n",
    "\n",
    "# delete the bucket\n",
    "response = s3.delete_bucket(Bucket=myBucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px dotted;color:coral\">\n",
    "<hr style=\"border:1px dotted;color:gold\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"color:gold\">Appendix - Jupyter Install Requirements (macOS)</p>\n",
    "#### <p style=\"color:deeppink\">- If you are running VSCode on a laptop, follow all steps below, including the following:</p>\n",
    "  - Credentials to the AWS account this notebook executes in is provided by AWS configure\n",
    "  - You must already have an IAM user with code (Command Line Interface) access and AWS access keys to be able to use these credentials in AWS configure  \n",
    "    \n",
    "  - arn:aws:iam::###########:user/simon-davies-cli created for this lab  \n",
    "\n",
    "#### <p style=\"color:deeppink\">- If you are running Jupyter inside an AWS Account, you don't need to do anything!</p>\n",
    "\n",
    "### <p style=\"color:gold\">1. Homebrew</p> \n",
    "If you haven't installed Homebrew, you can install it by running the following command here or in the terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "sudo /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"color:gold\">1.1 Virtual Environments</p> \n",
    "- You can create a virtual environment that ensures any libraries you install are restricted to the venv.\n",
    "  - https://code.visualstudio.com/docs/python/environments\n",
    "- To enable the virtual environment once you have created it, ensure you open the folder in vs code containing the notebook files, rather than individual notebook files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "sudo /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"color:gold\">1.2 Python</p> \n",
    "Once Homebrew is installed, you can install Python using the following command  \n",
    "*check what you have before installing/upgrading*  \n",
    "*you will need to quit and restart vsCode to use python once installed (or updated)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "python3 --version\n",
    "which python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "brew install python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"color:gold\">2. boto3 and other Python requirements</p> \n",
    "* boto3 must be installed on your client\n",
    "  * *Boto3 is the Amazon Web Services (AWS) Software Development Kit (SDK) for Python, which allows Python developers to write software that makes use of services like Amazon S3 and Amazon EC2.*\n",
    "  * https://boto3.amazonaws.com/v1/documentation/api/latest/index.html  \n",
    "  \n",
    "*check what you have before installing/upgrading*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "python3 -m pip show boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install -U boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"color:gold\">3. aws configure</p> \n",
    "*Configure aws configure with credentials, and a user that has all of the Bedrock IAM policies required*  \n",
    "https://docs.aws.amazon.com/bedrock/latest/userguide/security_iam_id-based-policy-examples.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "aws sts get-caller-identity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px dotted;color:gold\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
